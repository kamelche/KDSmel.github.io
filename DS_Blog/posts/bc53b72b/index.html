<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">

<script>
    (function(){
        if(''){
            if (prompt('Show me your password') !== ''){
                alert('Blah, wrong.');
                history.back();
            }
        }
    })();
</script>


<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






  
  
  <link rel="stylesheet" href="/lib/Han/dist/han.min.css?v=3.3">













  
  
  <link rel="stylesheet" href="/lib/fancybox/source/jquery.fancybox.css">







  

<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

<link rel="stylesheet" href="/css/main.css?v=7.1.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.2">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.1.2',
    sidebar: {"position":"right","display":"hide","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: true,
    fastclick: true,
    lazyload: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Maximal Margin Classifier What Is a Hyperplane? Hyperplane: In a p-dimensional space, a hyperplane is a flat affine subspace of dimension \(p − 1\).  e.g. in two dimensions, a hyperplane is a flat one">
<meta name="keywords" content="SVM">
<meta property="og:type" content="article">
<meta property="og:title" content="Study Note: SVM">
<meta property="og:url" content="https://nancyyanyu.github.io/posts/bc53b72b/index.html">
<meta property="og:site_name" content="Nancy&#39;s Notes">
<meta property="og:description" content="Maximal Margin Classifier What Is a Hyperplane? Hyperplane: In a p-dimensional space, a hyperplane is a flat affine subspace of dimension \(p − 1\).  e.g. in two dimensions, a hyperplane is a flat one">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://nancyyanyu.github.io/posts/bc53b72b/S1.png">
<meta property="og:image" content="https://nancyyanyu.github.io/posts/bc53b72b/S2.png">
<meta property="og:image" content="https://nancyyanyu.github.io/posts/bc53b72b/SVC1.png">
<meta property="og:image" content="https://nancyyanyu.github.io/posts/bc53b72b/SVC2.png">
<meta property="og:image" content="https://nancyyanyu.github.io/posts/bc53b72b/SVM1.png">
<meta property="og:image" content="https://nancyyanyu.github.io/posts/bc53b72b/SVM2.png">
<meta property="og:updated_time" content="2019-10-19T23:21:35.237Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Study Note: SVM">
<meta name="twitter:description" content="Maximal Margin Classifier What Is a Hyperplane? Hyperplane: In a p-dimensional space, a hyperplane is a flat affine subspace of dimension \(p − 1\).  e.g. in two dimensions, a hyperplane is a flat one">
<meta name="twitter:image" content="https://nancyyanyu.github.io/posts/bc53b72b/S1.png">



  <link rel="alternate" href="/atom.xml" title="Nancy's Notes" type="application/atom+xml">



  
  
  <link rel="canonical" href="https://nancyyanyu.github.io/posts/bc53b72b/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Study Note: SVM | Nancy's Notes</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Nancy's Notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Code changes world!</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-ml">

    
    
    
      
    

    

    <a href="/categories/Machine-Learning" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>ML</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-big-data">

    
    
    
      
    

    

    <a href="/categories/Big-Data" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Big Data</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-journal">

    
    
    
      
    

    

    <a href="/categories/Journal/" rel="section"><i class="menu-item-icon fa fa-fw fa-coffee"></i> <br>Journal</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://nancyyanyu.github.io/posts/bc53b72b/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nancy Yan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Nancy's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Study Note: SVM

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-06-12 16:48:50" itemprop="dateCreated datePublished" datetime="2019-06-12T16:48:50-05:00">2019-06-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-10-19 18:21:35" itemprop="dateModified" datetime="2019-10-19T18:21:35-05:00">2019-10-19</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article: </span>
                
                <span title="Symbols count in article">11k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">10 mins.</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h1 id="maximal-margin-classifier">Maximal Margin Classifier</h1>
<h2 id="what-is-a-hyperplane">What Is a Hyperplane?</h2>
<p><strong>Hyperplane</strong>: In a p-dimensional space, a hyperplane is a flat affine subspace of dimension <span class="math inline">\(p − 1\)</span>.</p>
<ul>
<li>e.g. in two dimensions, a hyperplane is a flat one-dimensional subspace—in other words, a line.</li>
</ul>
<p><strong>Mathematical definition of a hyperplane</strong>: <span class="math display">\[
\beta_0+\beta_1X_1+\beta_2X_2,...+\beta_pX_p=0, \quad (9.1)
\]</span></p>
<ul>
<li>Any <span class="math inline">\(X = (X_1,X_2,…X_p)^T\)</span> for which (9.1) holds is a point on the hyperplane.</li>
</ul>
<a id="more"></a>
<h2 id="classification-using-a-separating-hyperplane">Classification Using a Separating Hyperplane</h2>
<p><strong>Setting</strong>:</p>
<ul>
<li><span class="math inline">\(n \times p\)</span> data matrix <span class="math inline">\(X\)</span> that consists of <span class="math inline">\(n\)</span> training observations in p-dimensional space</li>
<li>These observations fall into two classes—that is, $y_1, . . . , y_n {−1, 1} $.</li>
<li>Test observation: a p-vector of observed features <span class="math inline">\(x^∗ =\{x^∗_1 . . . x^∗_p\}^T\)</span>.</li>
</ul>
<p><strong>Separating hyperplane</strong> has the property that: <span class="math display">\[
y_i(\beta_0+\beta_1x_{i1}+\beta_2x_{i2},...+\beta_px_{ip})&gt;0, \quad (9.8)
\]</span></p>
<ul>
<li>for all i=1,…,n</li>
</ul>
<p>We classify the test observation <span class="math inline">\(x^*\)</span> based on the sign of <span class="math inline">\(f(x^∗) = \beta_0+\beta_1x_{1}^*+\beta_2x_{2}^*,...+\beta_px_{p}^*\)</span>.</p>
<ul>
<li>If <span class="math inline">\(f(x^∗)\)</span> is positive, then we assign the test observation to class 1, and if f(x∗) is negative, then we assign it to class −1.</li>
<li><strong>Magnitude</strong> of <span class="math inline">\(f(x^∗)\)</span>. If <span class="math inline">\(f(x^∗)\)</span>is far from zero, then this means that <span class="math inline">\(x^∗\)</span> lies far from the hyperplane,and so we can be confident about our class assignment for <span class="math inline">\(x^∗\)</span>.</li>
</ul>
<p><img src="./S1.png" width="600" aign="middle"></p>
<h2 id="the-maximal-margin-classifier">The Maximal Margin Classifier</h2>
<p><strong><em>Margin</em></strong>: the smallest (perpendicular) distance from each training observation to a given separating hyperplane <span class="math inline">\(\Rightarrow\)</span> the minimal distance from the observations to the hyperplane.</p>
<p><strong><em>Maximal margin hyperplane</em></strong>: the separating hyperplane that is farthest from the training observations.</p>
<ul>
<li>The maximal margin hyperplane is the separating hyperplane for which the <em>margin</em> is <strong>largest</strong></li>
<li>Overfitting when <span class="math inline">\(p\)</span> is large.</li>
</ul>
<p><strong><em>Maximal margin classifier</em></strong>: classify a test observation based on which side of the maximal margin hyperplane it lies.</p>
<p><strong><em>Support vectors</em></strong>: training observations that are equidistant from the maximal margin hyperplane that indicate <em>the width of the margin</em>.</p>
<ul>
<li>They “support” the maximal margin hyperplane in the sense vector that if these points were moved slightly then the maximal margin hyperplanewould move as well.</li>
<li><em>The maximal margin hyperplane depends directly on the support vectors, but not on the other observations</em></li>
</ul>
<p><img src="./S2.png" width="600"></p>
<h2 id="construction-of-the-maximal-margin-classifier">Construction of the Maximal Margin Classifier</h2>
<p>The maximal margin hyperplane is the solution to the optimization problem <span class="math display">\[
\max_{\beta_0,...\beta_p} M \\
s.t.  \sum_{j=1}^p \beta_j^2=1,  \quad (9.10) \\
 y_i(\beta_0+\beta_1x_{i1}+\beta_2x_{i2},...+\beta_px_{ip})&gt;M \quad \forall i=1,..,n.  \quad (9.11)
\]</span></p>
<ul>
<li>The constraint in (9.11) in fact requires that each observation be on the correct side of the hyperplane, with some cushion, provided that <strong>margin</strong> <span class="math inline">\(M\)</span> is positive.)</li>
<li>The constraint in (9.10) makes sure the perpendicular distance from the i-th observation to the hyperplane is given by</li>
</ul>
<p><span class="math display">\[
y_i(\beta_0+\beta_1x_{i1}+\beta_2x_{i2},...+\beta_px_{ip})
\]</span></p>
<h1 id="support-vector-classifiers">Support Vector Classifiers</h1>
<h2 id="overview-of-the-support-vector-classifier">Overview of the Support Vector Classifier</h2>
<p><strong>Maximal margin hyperplane</strong> is extremely sensitive to a change in a single observation suggests that it may have <strong><em>overfit</em></strong> the training data.</p>
<p>In this case, we might be willing to consider a classifier based on a hyperplane that does not perfectly separate the two classes, in the interest of</p>
<ul>
<li>Greater <em>robustness</em> to individual observations, and</li>
<li>Better classification of most of the training observations.</li>
</ul>
<p><strong><em>Support Vector Classifier (Soft Margin Classifier)</em></strong>: Rather than seeking the largest possible margin that every observation is not only on the correct side of the hyperplane but also on the correct side of the margin, we instead allow some observationsto be on the incorrect side of the margin, or even the incorrect side of the hyperplane.</p>
<p><img src="./SVC1.png" width="600"></p>
<h2 id="details-of-the-support-vector-classifier">Details of the Support Vector Classifier</h2>
<p><strong>Optimization problem</strong>: <span class="math display">\[
\max_{\beta_0,...\beta_p,\epsilon_1,..,\epsilon_n} M \\
s.t.  \sum_{j=1}^p \beta_j^2=1,  \quad (9.13) \\
 y_i(\beta_0+\beta_1x_{i1}+\beta_2x_{i2},...+\beta_px_{ip})&gt;M(1-\epsilon_i) \quad \forall i=1,..,n.  \quad (9.14) \\
 \epsilon_i\geq0,\sum_{i=1}^p\epsilon_i \leq C, \quad (9.15)
\]</span></p>
<ul>
<li><strong><em>Slack variables</em></strong>: <span class="math inline">\(\epsilon_1,..,\epsilon_n\)</span> - allow individual observations to be on the wrong side of the margin or the hyperplane
<ul>
<li><span class="math inline">\(\epsilon_i=0\)</span>: the i-th observation is on the correct side of the <em>margin</em></li>
<li><span class="math inline">\(\epsilon_i &gt;0\)</span>: the i-th observation is on the wrong side of the <em>margin</em> <span class="math inline">\(\Rightarrow\)</span> i-th observation <strong><em>violated</em></strong> the margin.</li>
<li><span class="math inline">\(\epsilon_i &gt;1\)</span>: the i-th observation is on the wrong side of the <em>hyperplane</em></li>
</ul></li>
<li>Classify the test observation based on the sign of <span class="math inline">\(f(x^∗) = \beta_0+\beta_1x_{1}^*+\beta_2x_{2}^*,...+\beta_px_{p}^*\)</span>.</li>
<li><strong><em>Tuning parameter C</em></strong>: <span class="math inline">\(C\)</span> bounds the sum of the <span class="math inline">\(\epsilon_i\)</span>'s, and so it determines the number and severity of the violationsto the margin(and to the hyperplane) that we will tolerate. $
<ul>
<li><strong><em>budget</em></strong> for the amount that the margin can be violated by the <span class="math inline">\(n\)</span> observations.</li>
<li>Generally chosen via <em>cross-validation</em>.</li>
<li><span class="math inline">\(C\)</span> controls the <strong>bias-variance trade-off</strong> of the support vector classifier.
<ul>
<li>C is small: a classifier highly fit to the data, fewersupport vectors <span class="math inline">\(\Rightarrow\)</span> low bias , high variance;</li>
<li>C is large: margin wider, many support vectors <span class="math inline">\(\Rightarrow\)</span> high bias , low variance;</li>
</ul></li>
</ul></li>
</ul>
<p><img src="./SVC2.png" width="600"></p>
<p><strong>Properties</strong>:</p>
<ul>
<li>Only observations that either <em>lie on the margin or that violate the margin</em> (<strong>support vectors</strong>) will affect the hyperplane, and hence the classifier obtained.</li>
<li>The fact that the support vector classifier’s decision rule is based only on a potentially small subset of the training observations (the <strong><em>support vectors</em></strong>) means that it is quite <strong>robust</strong> to the behavior of observations that are far away from the hyperplane.
<ul>
<li>Different from LDA which depends on the mean of <em>all</em> of the observations within each class, as well as the <em>within-class covariance matrix</em> computed using all of the observations</li>
</ul></li>
</ul>
<h1 id="support-vector-machines">Support Vector Machines</h1>
<h2 id="svms-with-kernel">SVMs with Kernel</h2>
<p>The <strong><em>support vector machine (SVM)</em></strong> is an extension of the support vector classifier that results from enlarging the feature space using <strong>kernels</strong>.</p>
<p>The <strong><em>solution to the support vector classifier problem</em></strong> involves only the <strong><em>inner products</em></strong> of the observations: <span class="math display">\[
\langle x_i,x_{i^{&#39;}} \rangle =\sum_{j=1}^px_{ij}x_{i^{&#39;}j}
\]</span> (Details won't be discussed in this note)</p>
<p>The <strong>linear support vector classifier</strong> can be represented as <span class="math display">\[
f(x)=\beta_0+\sum_{i=1}^n \alpha_i \langle x,x_i \rangle
\]</span></p>
<ul>
<li><span class="math inline">\(α_i\)</span> is nonzero only for the support vectors in the solution—that is, if a training observation is not a support vector, then its <span class="math inline">\(α_i\)</span>equals zero.</li>
</ul>
<p>So if <span class="math inline">\(S\)</span> is the collection of indices of these support points: <span class="math display">\[
f(x)=\beta_0+\sum_{i \in S}^n \alpha_i \langle x,x_i \rangle
\]</span> <strong>Generalization</strong>: <em>Kernel</em> <span class="math display">\[
K(x_i,x_{i^{&#39;}})
\]</span> <strong>Kernel</strong>: Kernel is a function that quantifies the similarity of two observations.</p>
<ul>
<li><strong><em>Linear kernel</em></strong>: <span class="math inline">\(K(x_i,x_{i^{&#39;}})=\sum_{j=1}^px_{ij}x_{i^{&#39;}j}\)</span>
<ul>
<li>Linear kernel essentially quantifies the similarity of a pair of observations using <strong>Pearson</strong> (standard) correlation.</li>
</ul></li>
<li><strong><em>Polynomial kernel</em></strong> of degree d: <span class="math inline">\(K(x_i,x_{i^{&#39;}})=(1+\sum_{j=1}^px_{ij}x_{i^{&#39;}j})^d\)</span>
<ul>
<li>fitting a support vector classifier in a higher-dimensional space involving polynomials of degree <span class="math inline">\(d\)</span>.</li>
</ul></li>
<li><strong><em>Radial kernel</em></strong>: <span class="math inline">\(K(x_i,x_{i^{&#39;}})=\exp(-\gamma \sum_{j=1}^p(x_{ij}-x_{i^{&#39;}j})^2)\)</span>
<ul>
<li>Radial kernel has very <em>local</em> behavior: only nearby training observations have an effect on the class label of a test observation
<ul>
<li>If a given test observation <span class="math inline">\(x^∗ = (x^∗_1 . . .x^∗_p)^T\)</span> is far from a training observation <span class="math inline">\(x_i\)</span> in terms of <strong><em>Euclidean distance</em></strong>; <span class="math inline">\(\Rightarrow\)</span> $ _{j=1}<sup>p(x_{ij}-x_{i</sup>{'}j})^2 $ will be large <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(K(x_i,x_{i^{&#39;}})=\exp(-\gamma \sum_{j=1}^p(x_{ij}-x_{i^{&#39;}j})^2)\)</span> will be very tiny. <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(x_i\)</span> will play virtually no role in <span class="math inline">\(f(x^∗)\)</span>.</li>
</ul></li>
</ul></li>
</ul>
<p><strong><em>Support Vector Machine</em></strong>: When the support vector classifieris combined with a non-linear kernel, the resulting classifier is known as a support vector machine. <span class="math display">\[
f(x)=\beta_0+\sum_{i \in S}^n \alpha_i K(x,x_i)
\]</span> <img src="./SVM1.png"></p>
<p><strong>Advantage of Kernel over enlarging the feature space using functions of the original features: </strong></p>
<ul>
<li><strong><em>Computational</em></strong>: one need only compute <span class="math inline">\(K(x_i,x_{i^{&#39;}})\)</span> for all <span class="math inline">\(\left(\begin{array}{c}n\\ 2\end{array}\right)\)</span> distinct pairs <span class="math inline">\(i, i^{&#39;}\)</span>. This can bedone without explicitly working in the <em>enlarged feature space.</em>
<ul>
<li><strong>Curse of dimensionality</strong>: for some kernels, such as the radial kernel, the feature space is implicit and infinite-dimensional.</li>
</ul></li>
</ul>
<h2 id="svms-with-more-than-two-classes">SVMs with More than Two Classes</h2>
<h3 id="one-versus-one-classification">One-Versus-One Classification</h3>
<p>A <strong><em>one-versus-one</em></strong> or <strong><em>all-pairs</em></strong> approach constructs <span class="math inline">\(\left(\begin{array}{c}K\\ 2\end{array}\right)\)</span> SVMs, each of which compares a pair of classes</p>
<ol type="1">
<li>One such SVM might compare the <span class="math inline">\(k\)</span>-th class, coded as +1, to the <span class="math inline">\(k^{&#39;}\)</span>-th class, codedas −1.</li>
<li>We classify a test observation using each of the <span class="math inline">\(\left(\begin{array}{c}K\\ 2\end{array}\right)\)</span> classifiers.</li>
<li>We tally the number of times that the test observation is assigned to each of the K classes.</li>
<li>The final classification is performed by assigning the test observation to the class to which it was most frequently assigned in these <span class="math inline">\(\left(\begin{array}{c}K\\ 2\end{array}\right)\)</span> pairwise classifications.</li>
</ol>
<h3 id="one-versus-all-classification">One-Versus-All Classification</h3>
<p>The <strong><em>one-versus-all</em></strong> approach:</p>
<ol type="1">
<li>We fit <span class="math inline">\(K\)</span> SVMs, each time comparing one of all the K classes to the remaining K − 1 classes.</li>
<li>Let <span class="math inline">\(β_{0k}, β_{1k}, . . . , β_{pk}\)</span> denote the parameters that result from fitting an SVM comparing the kth class(coded as +1) to the others (coded as −1).</li>
<li>Let $ x^∗$ denote a test observation. We assign the observation to the class for which <span class="math inline">\(β_{0k}x_1^*+β_{1k}x_2^*+, . . . ,+ β_{pk}x_p^*\)</span> is largest, as this amounts to a high level of confidence that the test observation belongs to the kth class rather than to any of the other classes.</li>
</ol>
<h2 id="relationship-to-logistic-regression">Relationship to Logistic Regression</h2>
<p>Rewrite the criterion (9.12)–(9.15) [look at last post] for fitting the support vector classifier <span class="math inline">\(f(X) = β_0 + β_1X_1 + . . . + β_pX_p\)</span> as <span class="math display">\[
\min_{\beta_0,...,\beta_p}\left\{ \sum_{i=1}^n\max[0,1-y_If(x_i)]+\lambda\sum_{j=1}^p\beta_j^2 \right\}
\]</span></p>
<ul>
<li>λ is small: few violations to the margin ; high-variance, low-bias; <span class="math inline">\(\Leftrightarrow\)</span> small <span class="math inline">\(C\)</span>;</li>
</ul>
<p><strong>“Loss + Penalty” form</strong>: <span class="math display">\[
\min_{\beta_0,...,\beta_p}\left\{ L(\mathbf{X},\mathbf{y},\beta)+\lambda P(\beta) \right\}
\]</span></p>
<ul>
<li><span class="math inline">\(L(\mathbf{X},\mathbf{y},\beta)\)</span> : loss function</li>
<li><span class="math inline">\(P(\beta)\)</span>: penalty function</li>
</ul>
<p><strong>Ridge regression and the lasso</strong>: <span class="math display">\[
L(\mathbf{X},\mathbf{y},\beta)=\sum_{i=1}^n \left( y_i-\beta_0-\sum_{j=1}^p x_{ij}\beta_j \right)^2 \\
P(\beta) = \sum_{j=1}^p \beta_j^2 \quad ridge \, regression \\
P(\beta) = \sum_{j=1}^p |\beta_j| \quad lasso
\]</span> <strong>SVM</strong>: <strong><em>hindge loss</em></strong> <span class="math display">\[
L(\mathbf{X},\mathbf{y},\beta)=\sum_{i=1}^n \max[0,1-y_i(\beta_0+\beta_1x_{i1}+,,,+\beta_px_{ip})]
\]</span> <img src="SVM2.png"></p>
<ul>
<li>Due to thesimilarities between their loss functions, logistic regression and the supportvector classifier often give very similar results.</li>
<li>When the classes are well separated, SVMs tend to behave better than logistic regression</li>
</ul>
<hr>
<p><strong>Ref:</strong></p>
<p>James, Gareth, et al. <em>An introduction to statistical learning</em>. Vol. 112. New York: springer, 2013.</p>
<p>Hastie, Trevor, et al. &quot;The elements of statistical learning: data mining, inference and prediction.&quot; <em>The Mathematical Intelligencer</em> 27.2 (2005): 83-85</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/SVM/" rel="tag"># SVM</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/posts/6bd38994/" rel="prev" title="Machine Learning Q&A Part I: Learning Theory & Model Selection">
                Machine Learning Q&A Part I: Learning Theory & Model Selection <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Nancy Yan</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">44</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">34</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://github.com/nancyyanyu" title="GitHub &rarr; https://github.com/nancyyanyu" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#maximal-margin-classifier"><span class="nav-number">1.</span> <span class="nav-text">Maximal Margin Classifier</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#what-is-a-hyperplane"><span class="nav-number">1.1.</span> <span class="nav-text">What Is a Hyperplane?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#classification-using-a-separating-hyperplane"><span class="nav-number">1.2.</span> <span class="nav-text">Classification Using a Separating Hyperplane</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#the-maximal-margin-classifier"><span class="nav-number">1.3.</span> <span class="nav-text">The Maximal Margin Classifier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#construction-of-the-maximal-margin-classifier"><span class="nav-number">1.4.</span> <span class="nav-text">Construction of the Maximal Margin Classifier</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#support-vector-classifiers"><span class="nav-number">2.</span> <span class="nav-text">Support Vector Classifiers</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#overview-of-the-support-vector-classifier"><span class="nav-number">2.1.</span> <span class="nav-text">Overview of the Support Vector Classifier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#details-of-the-support-vector-classifier"><span class="nav-number">2.2.</span> <span class="nav-text">Details of the Support Vector Classifier</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#support-vector-machines"><span class="nav-number">3.</span> <span class="nav-text">Support Vector Machines</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#svms-with-kernel"><span class="nav-number">3.1.</span> <span class="nav-text">SVMs with Kernel</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#svms-with-more-than-two-classes"><span class="nav-number">3.2.</span> <span class="nav-text">SVMs with More than Two Classes</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#one-versus-one-classification"><span class="nav-number">3.2.1.</span> <span class="nav-text">One-Versus-One Classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#one-versus-all-classification"><span class="nav-number">3.2.2.</span> <span class="nav-text">One-Versus-All Classification</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#relationship-to-logistic-regression"><span class="nav-number">3.3.</span> <span class="nav-text">Relationship to Logistic Regression</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Nancy Yan</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="Symbols count total">518k</span>
  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>





  



  






  



  
    
    
      
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script>



  
  



  
  



  
  



  
  
  <script id="ribbon" size="300" alpha="0.6" zindex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>





  
  <script src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script>

  
  <script src="//cdn.jsdelivr.net/fastclick/1.0.6/fastclick.min.js"></script>

  
  <script src="//cdn.jsdelivr.net/npm/jquery-lazyload@1/jquery.lazyload.min.js"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script src="/lib/fancybox/source/jquery.fancybox.pack.js"></script>

  
  <script src="/lib/three/three.min.js"></script>

  
  <script src="/lib/three/three-waves.min.js"></script>

  
  <script src="/lib/three/canvas_lines.min.js"></script>

  
  <script src="/lib/three/canvas_sphere.min.js"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.2"></script>




  
  <script src="/js/scrollspy.js?v=7.1.2"></script>
<script src="/js/post-details.js?v=7.1.2"></script>



  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  


  
    
<!-- LOCAL: You can save these files to your site and update links -->

  
  <script src="https://www.wenjunjiang.win/js/gitment.js"></script>

<link rel="stylesheet" href="https://www.wenjunjiang.win/css/gitment.css">
<!-- END LOCAL -->


<script>
  function renderGitment() {
    var gitment = new Gitment({
      id: window.location.pathname,
      owner: 'nancyyanyu',
      repo: 'nancyyanyu.github.io',
      
      oauth: {
      
      
        client_secret: '75adc257166813deff478053f3f05133285d6cf0',
      
        client_id: '90ddd3d00d8930cb0d84'
      }
    });
    gitment.render('gitment-container');
  }

  
    renderGitment();
  
</script>

  




  




  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>

<script type="text/javascript" src="/js/src/dynamic_bg.js"></script>

